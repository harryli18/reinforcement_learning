{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SA_Q_learning_v5_grid_search.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"_ZsNQ2jWhsST","colab_type":"code","colab":{}},"cell_type":"code","source":["# Import the useful libraries \n","import numpy as np\n","import pandas as pd\n","import os\n","from random import randint\n","import matplotlib.pyplot as plt\n","from google.colab import files\n","import time"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NdB5iMCOiL1B","colab_type":"code","outputId":"c5f19339-7cf9-4316-92b1-4cd997a54815","executionInfo":{"status":"ok","timestamp":1552761013495,"user_tz":0,"elapsed":1022,"user":{"displayName":"Xin Li","photoUrl":"","userId":"09691038738357971763"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["# Define R Matrix \n","\n","R = np.matrix([[0, 0, np.nan, np.nan, 0, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan],\n","                [0, 0, 0, np.nan, 0, 0, np.nan, np.nan, np.nan, np.nan, np.nan],\n","                [np.nan, 0, 0, 0, np.nan, np.nan, 100, np.nan, np.nan, np.nan, np.nan],\n","                [np.nan, np.nan, 0, 0, np.nan, np.nan, 100, np.nan, np.nan, np.nan, np.nan],\n","                [0, 0, np.nan, np.nan, 0, 0, np.nan, np.nan, 0, 0, np.nan],\n","                [np.nan, 0, np.nan, np.nan, 0, 0, 100, 0, np.nan, np.nan, np.nan],\n","                [np.nan, np.nan, 0, 0, np.nan, 0, 100, 0, np.nan, np.nan, np.nan],\n","                [np.nan, np.nan, np.nan, np.nan, np.nan, 0, 100, 0, np.nan, np.nan, 0],\n","                [np.nan, np.nan, np.nan, np.nan, 0, np.nan, np.nan, np.nan, 0, 0, np.nan],\n","                [np.nan, np.nan, np.nan, np.nan, 0, np.nan, np.nan, np.nan, 0, 0, 0],\n","                [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, 0, np.nan, 0, 0]])\n","\n","print(R)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[[  0.   0.  nan  nan   0.  nan  nan  nan  nan  nan  nan]\n"," [  0.   0.   0.  nan   0.   0.  nan  nan  nan  nan  nan]\n"," [ nan   0.   0.   0.  nan  nan 100.  nan  nan  nan  nan]\n"," [ nan  nan   0.   0.  nan  nan 100.  nan  nan  nan  nan]\n"," [  0.   0.  nan  nan   0.   0.  nan  nan   0.   0.  nan]\n"," [ nan   0.  nan  nan   0.   0. 100.   0.  nan  nan  nan]\n"," [ nan  nan   0.   0.  nan   0. 100.   0.  nan  nan  nan]\n"," [ nan  nan  nan  nan  nan   0. 100.   0.  nan  nan   0.]\n"," [ nan  nan  nan  nan   0.  nan  nan  nan   0.   0.  nan]\n"," [ nan  nan  nan  nan   0.  nan  nan  nan   0.   0.   0.]\n"," [ nan  nan  nan  nan  nan  nan  nan   0.  nan   0.   0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"ps9REqUJiNuc","colab_type":"code","outputId":"d3a22fc0-6648-4324-83ff-e87ee97e12e7","executionInfo":{"status":"ok","timestamp":1552761013497,"user_tz":0,"elapsed":889,"user":{"displayName":"Xin Li","photoUrl":"","userId":"09691038738357971763"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["# Initialise Q Matrix \n","Q = np.matrix(np.zeros([11,11]))\n","\n","print(Q)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"Yxs41JiKiO98","colab_type":"code","colab":{}},"cell_type":"code","source":["def q_learning(alpha, gamma, epsilon, decay):\n","    \n","  # initialise current state in random\n","  current_state = randint(0, 10)\n","  \n","  # check available actions in the current state\n","  current_state_row = R[current_state,]\n","  av_act = np.where(current_state_row >= 0)[1]\n","  \n","  # randomly select the next action and record in steps\n","  next_action = int(np.random.choice(av_act,1))\n","  \n","  # epislon greedy policy\n","  if np.random.uniform(0, 1) > epsilon:\n","    one_step_ahead_q_value = np.max(Q[next_action, :])\n","  else:\n","    one_step_ahead_q_value = np.random.choice(np.array(Q[next_action,:]).ravel())\n","    \n","  # update Q-matrix\n","  Q[current_state, next_action] = Q[current_state, next_action] + alpha * (R[current_state, next_action] + gamma * one_step_ahead_q_value - Q[current_state, next_action])\n","  \n","  # update epsilon value\n","  epsilon *= decay\n","  \n","  # return Q-matrix and number of steps\n","  return Q, alpha, gamma, epsilon, decay"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ELnUqwwwiRBn","colab_type":"code","colab":{}},"cell_type":"code","source":["def evaluate(Q, episode, alpha, gamma, epsilon, decay):\n","  \n","  # initiate current state\n","#   current_state = randint(0,10)\n","  current_state = 8\n","  steps = [current_state]\n","  reward = 0\n","  \n","  # set rule if initiated from Station 7\n","  if current_state == 6:\n","    reward += np.max(Q[current_state, :])\n","  \n","  # step for start from other stations\n","  else:\n","    while current_state != 6:\n","      \n","      # check available actions, particular for early episode that Q value is 0 \n","      current_state_row = R[current_state, :]\n","      av_act = np.where(current_state_row >= 0)[1]\n","      \n","      # index for maximum value\n","      max_index = np.where(Q[current_state,:] == np.max(Q[current_state, av_act]))[1]\n","      \n","      if max_index.shape[0] > 1:\n","        next_step = int(np.random.choice(max_index, size = 1))\n","      else:\n","        next_step = int(max_index)\n","      \n","      # append next action and reward\n","      next_reward = np.max(Q[current_state, max_index])\n","      \n","      steps.append(next_step)\n","      reward += next_reward\n","      current_state = next_step\n","      \n","  \n","  average_reward.append((episode, alpha, gamma, epsilon, decay, reward/len(steps)))  \n","  step_cont.append((episode, alpha, gamma, epsilon, decay, len(steps)))\n","  \n","  return average_reward, step_cont"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KmAx8ch9iUQc","colab_type":"code","colab":{}},"cell_type":"code","source":["# Define initial parameters \n","alphas = [0.05, 0.1, 0.2, 0.5, 0.7, 0.9, 1] # alpha is the learning rate\n","gammas = [0.8] # gamma is the discount factor \n","epsilons = [0.1] # epsilon is the exploration factor\n","decays = [0.95] # df is the decay factor for epsilon"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l5UnT6_FiV3W","colab_type":"code","outputId":"bb4ddeb6-bd4e-4784-a876-b188e1212d17","executionInfo":{"status":"ok","timestamp":1552761015234,"user_tz":0,"elapsed":551,"user":{"displayName":"Xin Li","photoUrl":"","userId":"09691038738357971763"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"cell_type":"code","source":["for alpha in alphas:\n","    for gamma in gammas:\n","        for epsilon in epsilons:\n","            for decay in decays:\n","                print(alpha,gamma,epsilon,decay)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["0.05 0.8 0.1 0.95\n","0.1 0.8 0.1 0.95\n","0.2 0.8 0.1 0.95\n","0.5 0.8 0.1 0.95\n","0.7 0.8 0.1 0.95\n","0.9 0.8 0.1 0.95\n","1 0.8 0.1 0.95\n"],"name":"stdout"}]},{"metadata":{"id":"922ajyexiXON","colab_type":"code","outputId":"a73e4aab-1613-4934-a53d-7f95ece15a9a","executionInfo":{"status":"ok","timestamp":1552761017130,"user_tz":0,"elapsed":898,"user":{"displayName":"Xin Li","photoUrl":"","userId":"09691038738357971763"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"cell_type":"code","source":["average_reward = []\n","step_cont = []\n","\n","start = time.time()\n","\n","for alpha in alphas:\n","  for gamma in gammas:\n","    for decay in decays:\n","      for epsilon in epsilons:\n","        for episode in range(100):\n","\n","          Q, alpha, gamma, epsilon, decay = q_learning(alpha, gamma, epsilon, decay)\n","    \n","          if np.matrix.max(Q) > 0:\n","            Q_norm = (Q/np.matrix.max(Q)*100)\n","          else:\n","            Q_norm = Q\n","\n","          average_reward, step_cont = evaluate(Q_norm, episode, alpha, gamma, epsilon, decay)\n","      \n","      # Reset the Q-matrix and epsilon to initial value\n","      Q = np.matrix(np.zeros([11,11]))\n","      epsilon = epsilon\n","          \n","end = time.time()\n","                  \n","print(Q_norm.astype(int))\n","# print(average_reward)\n","# print(step_cont)\n","print('Time used :', end-start, 'seconds')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in greater_equal\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in greater_equal\n"],"name":"stderr"},{"output_type":"stream","text":["[[  0  24   0   0   0   0   0   0   0   0   0]\n"," [  0  24  30   0  19  24   0   0   0   0   0]\n"," [  0  24  49  39   0   0  62   0   0   0   0]\n"," [  0   0  49  80   0   0 100   0   0   0   0]\n"," [  0  24   0   0  19   0   0   0  15   0   0]\n"," [  0  24   0   0  19  24   0  30   0   0   0]\n"," [  0   0  49  30   0  24  77  30   0   0   0]\n"," [  0   0   0   0   0  24  37  30   0   0  24]\n"," [  0   0   0   0   0   0   0   0  15  19   0]\n"," [  0   0   0   0   0   0   0   0   0  19  24]\n"," [  0   0   0   0   0   0   0  30   0   0  24]]\n","Time used : 0.32828474044799805 seconds\n"],"name":"stdout"}]},{"metadata":{"id":"WgsykM0nibX0","colab_type":"code","outputId":"5d8467af-b6a5-4438-f2cd-da2a9f14e55d","executionInfo":{"status":"ok","timestamp":1552761018684,"user_tz":0,"elapsed":539,"user":{"displayName":"Xin Li","photoUrl":"","userId":"09691038738357971763"}},"colab":{"base_uri":"https://localhost:8080/","height":212}},"cell_type":"code","source":["df_reward = pd.DataFrame.from_records(average_reward, columns = ['episode', 'alpha', 'gamma', 'epsilon', 'decay', 'Average Reward Per Step'])\n","df_step = pd.DataFrame.from_records(step_cont, columns = ['episode', 'alpha', 'gamma', 'epsilon', 'decay','Steps'])\n","\n","df = pd.merge(df_reward, df_step, on=['episode', 'alpha', 'gamma', 'epsilon', 'decay'])\n","print(df.shape)\n","df.head(5)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["(700, 7)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>episode</th>\n","      <th>alpha</th>\n","      <th>gamma</th>\n","      <th>epsilon</th>\n","      <th>decay</th>\n","      <th>Average Reward Per Step</th>\n","      <th>Steps</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.05</td>\n","      <td>0.8</td>\n","      <td>0.095000</td>\n","      <td>0.95</td>\n","      <td>0.0</td>\n","      <td>25</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.05</td>\n","      <td>0.8</td>\n","      <td>0.090250</td>\n","      <td>0.95</td>\n","      <td>0.0</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.05</td>\n","      <td>0.8</td>\n","      <td>0.085737</td>\n","      <td>0.95</td>\n","      <td>0.0</td>\n","      <td>19</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.05</td>\n","      <td>0.8</td>\n","      <td>0.081451</td>\n","      <td>0.95</td>\n","      <td>0.0</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.05</td>\n","      <td>0.8</td>\n","      <td>0.077378</td>\n","      <td>0.95</td>\n","      <td>0.0</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   episode  alpha  gamma   epsilon  decay  Average Reward Per Step  Steps\n","0        0   0.05    0.8  0.095000   0.95                      0.0     25\n","1        1   0.05    0.8  0.090250   0.95                      0.0     13\n","2        2   0.05    0.8  0.085737   0.95                      0.0     19\n","3        3   0.05    0.8  0.081451   0.95                      0.0      6\n","4        4   0.05    0.8  0.077378   0.95                      0.0      8"]},"metadata":{"tags":[]},"execution_count":9}]},{"metadata":{"id":"uRLw1Ox4ln2w","colab_type":"code","colab":{}},"cell_type":"code","source":["df.to_excel('grid_search.xlsx')\n","files.download('grid_search.xlsx')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZXuy-tpZdWpA","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}